{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbbe2036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from IPython.display import display\n",
    "import sys\n",
    "from scipy.stats import zscore, percentileofscore\n",
    "from scipy.spatial import distance\n",
    "from scipy.spatial.distance import mahalanobis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "008755e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edward.luca\\Github\\PLETHEDU\\cleancode\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa5d49f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "############################## SETTING PATHS ##################################################\n",
    "\n",
    "#ioxpath = r\"C:\\Users\\a.michaelson\\Github\\PLETHEDU\\cleancode\\Pre_cleaned_up_files\\29_1daypostSCI.xlsx\"\n",
    "\n",
    "\n",
    "#iox = pd.read_excel(ioxpath)                                                    #Read IOX excel file\n",
    "\n",
    "\n",
    "# lYSH CHANGE THIS!!!!! IOX Path (hold ctrl + shift on file and select copy path, leave r there)\n",
    "\n",
    "# Specify the path to the Excel file\n",
    "ioxpath = r\"C:\\Users\\edward.luca\\Github\\PLETHEDU\\cleancode\\Pre_cleaned_up_files\\29_1daypostSCI_2sheets.xlsx\"\n",
    "\n",
    "# Read the Excel file into a list of dataframes, one dataframe for each sheet\n",
    "xls = pd.ExcelFile(ioxpath)\n",
    "\n",
    "# Access the first sheet (index 0)\n",
    "first_sheet_name = xls.sheet_names[0]\n",
    "first_sheet_data = pd.read_excel(ioxpath, sheet_name=first_sheet_name)\n",
    "\n",
    "# Access the second sheet (index 1)\n",
    "second_sheet_name = xls.sheet_names[1]\n",
    "second_sheet_data = pd.read_excel(ioxpath, sheet_name=second_sheet_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2190697a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### CLEANING EXCEL FILE FUNCTIONS ######################################\n",
    "\n",
    "def cleanit(iox):\n",
    "    ############## DELETING ############################\n",
    "    df = iox\n",
    "\n",
    "    # Helps visualization\n",
    "    df.columns.values[6] = \"c6\"\n",
    "    \n",
    "    # Find the row index where \"parameter\" is present in the specified column\n",
    "    start_row = df[df[\"c6\"].str.contains(\"parameter\", na=False)].index[0]\n",
    "\n",
    "    # Read the Excel file again, skipping the rows before the row with \"parameter\"\n",
    "    df = pd.read_excel(ioxpath, skiprows = start_row + 1)\n",
    "    \n",
    "    # Delete last 6 rows\n",
    "    df.drop(df.tail(6).index, inplace = True)\n",
    "    \n",
    "    # Delete rows containing the word 'analyzer' and 'period-stop'\n",
    "    df.rename(columns={df.columns[5]: \"c5\"}, inplace=True)\n",
    "    df = df[~df[\"c5\"].astype(str).str.contains('analyzer')]\n",
    "    df = df[~df[\"c5\"].astype(str).str.contains('period-stop')]\n",
    "    df.rename(columns={df.columns[6]: \"c6\", df.columns[8]: \"c8\"}, inplace=True)\n",
    "    \n",
    "    # Populate column 'c8' with values from 'c6' until the next non-null value is encountered\n",
    "    df['c8'] = df.groupby(df['c6'].notnull().cumsum())['c6'].transform(lambda x: x.ffill())\n",
    "    \n",
    "    # Delete columns 0,5-8\n",
    "    df = df.drop(columns = df.columns[0])\n",
    "    df = df.drop(columns = df.columns[4:7])\n",
    "\n",
    "    # Delete rows 0-5\n",
    "    df = df.drop(labels = range(0,5), axis = 0)\n",
    "    \n",
    "    \n",
    "    ################# ADDING/MOVING ##################\n",
    "    df.columns.values[5] = \"c5\"\n",
    "    df = df.dropna(subset=[\"c5\"]) #Remove unwanted NaNs\n",
    "    df.insert(0, \"Sample\", df[\"c5\"])\n",
    "\n",
    "\n",
    "\n",
    "    ################# RENAMING ########################\n",
    "    df.columns.values[0] = \"Sample\"\n",
    "    df.columns.values[1] = \"CPU Date\"\n",
    "    df.columns.values[2] = \"CPU Time\"\n",
    "    df.columns.values[3] = \"Site Time\"\n",
    "    df.columns.values[4] = \"Period Time\"\n",
    "    df.columns.values[5] = \"Protocol Type\"\n",
    "    df.columns.values[6] = \"Storage ID\"\n",
    "    df.columns.values[7] = \"First Beat ID\"\n",
    "    df.columns.values[8] = \"Last Beat ID\"\n",
    "    df.columns.values[9] = \"Ti (msec)\"\n",
    "    df.columns.values[10] = \"Te (msec)\"\n",
    "    df.columns.values[15] = \"RT (msec)\"\n",
    "    df.columns.values[17] = \"P (msec)\"\n",
    "    df.columns.values[18] = \"f (bpm)\"\n",
    "    df.columns.values[19] = \"EIP (msec)\"\n",
    "    df.columns.values[20] = \"EEP (msec)\"\n",
    "    \n",
    "    \n",
    "    # Reset the row headers to start from 1\n",
    "    df = df.reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    pd.set_option('display.max_columns', None)  # None: Display all columns\n",
    "    pd.set_option('display.max_rows', None)  # None: Display all rows\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84038fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## ADD OTHER PLETHYSMOGRAPHY VALUES #########################\n",
    "def addvalues(df):\n",
    "    mid_df = df.copy()  # Create a copy of the original DataFrame to avoid modifying it\n",
    "    \n",
    "    # Define the weights for each variable\n",
    "    weights = {\n",
    "        'TV': 0.4,\n",
    "        'Ti (msec)': 0.2,\n",
    "        'Te (msec)': 0.2,\n",
    "        'PIF': 0.2\n",
    "    }\n",
    "    \n",
    "    \n",
    "    # Calculate the z-scores, percentiles, and Mahalanobis distances for each variable\n",
    "    for variable in ['TV', 'Ti (msec)', 'Te (msec)', 'PIF']:\n",
    "        mean = mid_df[variable].mean()\n",
    "        std = mid_df[variable].std()\n",
    "        mid_df[f'{variable}_ZScore'] = (mid_df[variable] - mean) / std\n",
    "        mid_df[f'{variable}_Percentile'] = mid_df[variable].rank(pct=True)\n",
    "        cov = np.cov(np.stack(mid_df[variable]), rowvar=False)\n",
    "        mean_vector = np.array([mean])\n",
    "        mid_df[f'{variable}_MahalanobisDistance'] = mid_df[variable].apply(\n",
    "            lambda x: distance.mahalanobis([x], mean_vector, cov)\n",
    "        )\n",
    "\n",
    "    # Calculate the weighted composite score\n",
    "    variables = ['TV', 'Ti (msec)', 'Te (msec)', 'PIF']\n",
    "    composite_score = np.zeros(len(mid_df))\n",
    "    for variable in variables:\n",
    "        composite_score += (\n",
    "            weights[variable] * mid_df[f'{variable}_ZScore'] +\n",
    "            weights[variable] * mid_df[f'{variable}_Percentile'] +\n",
    "            weights[variable] * mid_df[f'{variable}_MahalanobisDistance']\n",
    "        )\n",
    "\n",
    "    # Assign the composite score to a new column\n",
    "    mid_df['BreathIrregularityScore'] = composite_score\n",
    "\n",
    "    return mid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a57b23bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndef combineit(mid_df,co2):\\n    finaldf = mid_df\\n    \\n    # Append co2 to the right of mid_df with four spaces in between\\n    finaldf = pd.concat([finaldf, pd.DataFrame(columns=['', '', '', '']), co2], axis=1)\\n    \\n    \\n\\n    return finaldf\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "################## COMBINE IOX UPDATED DATAFRAME WITH CO2 DATAFRAME ##########\n",
    "'''\n",
    "def combineit(mid_df,co2):\n",
    "    finaldf = mid_df\n",
    "    \n",
    "    # Append co2 to the right of mid_df with four spaces in between\n",
    "    finaldf = pd.concat([finaldf, pd.DataFrame(columns=['', '', '', '']), co2], axis=1)\n",
    "    \n",
    "    \n",
    "\n",
    "    return finaldf\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "edbe1b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "####################### SAVE FINAL DATAFRAME AS EXCEL #########################\n",
    "def excel_saveit(df):\n",
    "\n",
    "    # lYSH CHANGE THIS!!!!! determining the path and name of the file \n",
    "    file_path = r\"C:\\Users\\a.michaelson\\Github\\PLETHEDU\\cleancode\\Post_cleaned_up_files\\29_1daypostSCI_clean.xlsx\"\n",
    "  \n",
    "    # saving the excel\n",
    "    df.to_excel(file_path, index = False)\n",
    "    #print('IOX + CO2 DataFrame is written to Excel File successfully.')\n",
    "    print('IOX DataFrame is written to Excel File successfully.')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8da09050",
   "metadata": {},
   "outputs": [],
   "source": [
    "####################### SAVE FINAL DATAFRAME AS EXCEL FOR 2 SHEETS #########################\n",
    "def excel_saveit(first_sheet_data, second_sheet_data):\n",
    "    \n",
    "    # Specify the path and name of the Excel file\n",
    "    file_path = r\"C:\\Users\\edward.luca\\Github\\PLETHEDU\\cleancode\\Post_cleaned_up_files\\29_1daypostSCI_2sheets_clean.xlsx\"\n",
    "\n",
    "    # Create an Excel writer object to save multiple sheets to the same file\n",
    "    with pd.ExcelWriter(file_path, engine='xlsxwriter') as writer:\n",
    "        # Write the first sheet to the Excel file\n",
    "        first_sheet_data.to_excel(writer, sheet_name='FirstSheetName', index=False) #LYSH CHANGE FIRST SHEET NAME HERE!!\n",
    "\n",
    "        # Write the second sheet to the Excel file\n",
    "        second_sheet_data.to_excel(writer, sheet_name='SecondSheetName', index=False) #LYSH CHANGE SECOND SHEET NAME HERE!!\n",
    "\n",
    "    print('Both DataFrames are written to the Excel file successfully.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "837a6a4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = cleanit(first_sheet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "840bd59f",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_df = addvalues(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fc39cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#excel_saveit(mid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d111627f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = cleanit(second_sheet_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a31f0a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "mid_df2 = addvalues(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83717e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#excel_saveit(mid_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "31fabac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Both DataFrames are written to the Excel file successfully.\n"
     ]
    }
   ],
   "source": [
    "excel_saveit(mid_df, mid_df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b41e4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
